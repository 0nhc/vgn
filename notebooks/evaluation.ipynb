{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Network inspection, learning curves, metrics, and grasp trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from pathlib2 import Path\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rospy\n",
    "\n",
    "from vgn.baselines import GPD\n",
    "from vgn import benchmark, vis\n",
    "from vgn.dataset import Dataset\n",
    "from vgn.detection import *\n",
    "from vgn.utils.transform import Rotation, Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node(\"vgn_evaluation\", anonymous=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network\n",
    "\n",
    "Compute loss and accuracy on test set, visualize failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Path(\"/home/michel/catkin_ws/src/vgn/data/runs/200713-2255,dataset=train,augment=True,net=conv,batch_size=32,lr=3e-04,rot-loss-only/vgn_conv_24.pth\")\n",
    "dataset = Path(\"/home/michel/catkin_ws/src/vgn/data/datasets/test\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = load_network(model, device)\n",
    "dataset = Dataset(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw ground truth and predictions for random samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "Metrics and failure cases of a clutter removal experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = Path(\"/home/michel/catkin_ws/src/vgn/data/experiments/gpd_deepen_positive_scores/test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grasps, success_rate, percent_cleared, planning_time = benchmark.compute_metrics(logdir)\n",
    "\n",
    "print(\"# grasps:       \", n_grasps)\n",
    "print(\"Success rate:   \", success_rate)\n",
    "print(\"Percent cleared:\", percent_cleared)\n",
    "print(\"Planning time:   {} +- {}\".format(planning_time[\"mean\"], planning_time[\"std\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize failure cases in rviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(logdir)\n",
    "failures = dataset.df[dataset.df[\"label\"] == 0].index.tolist()\n",
    "iterator = iter(failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize one by one\n",
    "i = next(iterator)\n",
    "print(i)\n",
    "dataset.draw(i, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate with some time delay\n",
    "for i in iterator:\n",
    "    dataset.draw(i, 0.05)\n",
    "    time.sleep(2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Curves\n",
    "\n",
    "Loss and grasp metrics vs training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_dir = Path(\"data/runs/200610-2009,dataset=train,augment=True,net=conv,batch_size=32,lr=3e-04\")\n",
    "exp_name = \"06_train_augment\"\n",
    "object_set = \"adversarial\"\n",
    "epochs_to_evaluate = [5, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run clutter removal experiment for each `epochs_to_evaluate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in epochs_to_evaluate:\n",
    "    model = run_dir / (\"vgn_conv_\" + str(epoch) + \".pth\")\n",
    "    logdir = Path(\"data\") / \"experiments\" / exp_name / object_set / str(epoch)    \n",
    "    \n",
    "    if logdir.exists():\n",
    "        continue  # manually delete folder to rerun benchmark\n",
    "\n",
    "    benchmark.run(TODO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read train and validation losses (csvs need to be downloaded from TensorBoard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(run_dir / \"train\" / \"loss.csv\")\n",
    "train_epochs = df[\"Step\"].to_numpy()\n",
    "train_loss = df[\"Value\"].to_numpy()\n",
    "\n",
    "df = pd.read_csv(run_dir / \"validation\" / \"loss.csv\")\n",
    "val_epochs = df[\"Step\"].to_numpy()\n",
    "val_loss = df[\"Value\"].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the benchmark metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"data\") / \"experiments\" / exp_name / object_set\n",
    "success_rates = []\n",
    "for epoch in epochs_to_evaluate:\n",
    "    log_dir = root / str(epoch)\n",
    "    success_rate, _, _ = benchmark.metrics(log_dir)\n",
    "    success_rates.append(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "l1, = ax1.plot(train_epochs, train_loss, color=\"C0\")\n",
    "l2,= ax1.plot(val_epochs, val_loss, color=\"C1\")\n",
    "l3, = ax2.plot(epochs_to_evaluate, success_rates, color=\"C2\")\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax2.set_ylabel(\"%\")\n",
    "\n",
    "ax1.legend([l1, l2], [\"train\", \"validation\"], loc=\"lower left\")\n",
    "ax2.legend([l3], [\"success rate\"], loc=\"upper right\")\n",
    "\n",
    "fig.suptitle(exp_name)\n",
    "fig_path = Path.home() / \"Desktop\" / (exp_name + \".png\")\n",
    "plt.savefig(str(fig_path))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance vs Amount of Scene Information\n",
    "\n",
    "Evaluate grasp performance with increasingly complete scene reconstructions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path(\"data/experiments/scene_information\")\n",
    "N = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grasp_planner = VGN(Path(\"/home/michel/catkin_ws/src/vgn/data/runs/200611-1140,dataset=train,augment=True,net=conv,batch_size=32,lr=3e-04/vgn_conv_30.pth\"))\n",
    "grasp_planner = GPD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,N):\n",
    "    benchmark.run(\n",
    "        grasp_planner,\n",
    "        root / \"gpd\" / str(n).zfill(2),\n",
    "        object_set=\"test\",\n",
    "        object_count=5,\n",
    "        rounds=40,\n",
    "        n=n,\n",
    "        N=N,\n",
    "        sim_gui=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot performance vs number of viewpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewpoints = np.arange(1,N)\n",
    "success_rates = {\"vgn\" : []}\n",
    "percent_cleared = {\"vgn\": []}\n",
    "\n",
    "for n in viewpoints:\n",
    "    res = benchmark.compute_metrics(root / \"vgn\" / str(n).zfill(2))\n",
    "    success_rates[\"vgn\"].append(res[1])\n",
    "    percent_cleared[\"vgn\"].append(res[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(viewpoints, success_rates[\"vgn\"], color=\"C0\", label=\"VGN\")\n",
    "ax.plot(viewpoints, percent_cleared[\"vgn\"], color=\"C0\", linestyle=\"--\")\n",
    "ax.set_ylim(0, 101)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
